{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d13b0a7-8b9f-4f26-a38a-98c7c80561ea",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75eb0a76-3d02-4e4d-8319-d94f056c4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d387a43-984e-4c04-9df0-78cc70ef501c",
   "metadata": {},
   "source": [
    "# Convolutional Layer Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d214d968-066e-44f5-9ecf-a8bea756294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionLayer:\n",
    "    def __init__(self, kernel_num, kernel_size):\n",
    "        self.kernel_num = kernel_num\n",
    "        self.kernel_size = kernel_size\n",
    "        self.kernels = np.random.randn(kernel_num, kernel_size, kernel_size) / (kernel_size ** 2)\n",
    "\n",
    "    def patches_generator(self, image):\n",
    "        image_h, image_w = image.shape\n",
    "        self.image = image\n",
    "\n",
    "        for h in range(image_h - self.kernel_size + 1):\n",
    "            for w in range(image_w - self.kernel_size +1):\n",
    "                patch = image[h:(h+self.kernel_size), w:(w+self.kernel_size)]\n",
    "                yield patch, h, w\n",
    "\n",
    "    def forward_prop(self, image):\n",
    "        image_h, image_w = image.shape\n",
    "        convolution_output = np.zeros((image_h - self.kernel_size + 1, image_w - self.kernel_size + 1, self.kernel_num))\n",
    "        for patch, h, w in self.patches_generator(image):\n",
    "            convolution_output[h, w] = np.sum(patch * self.kernels, axis=(1, 2))\n",
    "\n",
    "        return convolution_output\n",
    "\n",
    "    def back_prop(self, dE_dY, alpha):\n",
    "        dE_dk = np.zeros(self.kernels.shape)\n",
    "        for patch, h, w in self.patches_generator(self.image):\n",
    "            for f in range(self.kernel_num):\n",
    "                dE_dk[f] += patch * dE_dY[h, w, f]\n",
    "        self.kernels -= alpha*dE_dk\n",
    "        return dE_dk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50568aeb-9df7-4ecd-8519-015a883dc2c3",
   "metadata": {},
   "source": [
    "# Max Pooling Layer Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c68b165-86ba-4697-b564-dc0cfeb06031",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolingLayer:\n",
    "    def __init__(self, kernel_size):\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def patches_generator(self, image):\n",
    "        output_h = image.shape[0] // self.kernel_size\n",
    "        output_w = image.shape[1] // self.kernel_size\n",
    "        self.image = image \n",
    "\n",
    "        for h in range(output_h):\n",
    "            for w in range(output_w):\n",
    "                patch = image[(h*self.kernel_size):(h*self.kernel_size+self.kernel_size), (w*self.kernel_size):(w*self.kernel_size+self.kernel_size)]\n",
    "                yield patch, h, w\n",
    "\n",
    "    def forward_prop(self, image):\n",
    "        image_h, image_w, num_kernels = image.shape\n",
    "        max_pooling_output = np.zeros((image_h//self.kernel_size, image_w//self.kernel_size, num_kernels))\n",
    "\n",
    "        for patch, h, w in self.patches_generator(image):\n",
    "            max_pooling_output[h, w] = np.amax(patch, axis=(0, 1))\n",
    "\n",
    "        return max_pooling_output\n",
    "\n",
    "    def back_prop(self, dE_dY):\n",
    "        dE_dk = np.zeros(self.image.shape)\n",
    "        for patch,h,w in self.patches_generator(self.image):\n",
    "            image_h, image_w, num_kernels = patch.shape\n",
    "            max_val = np.amax(patch, axis=(0,1))\n",
    "\n",
    "            for idx_h in range(image_h):\n",
    "                for idx_w in range(image_w):\n",
    "                    for idx_k in range(num_kernels):\n",
    "                        if patch[idx_h,idx_w,idx_k] == max_val[idx_k]:\n",
    "                            dE_dk[h*self.kernel_size+idx_h, w*self.kernel_size+idx_w, idx_k] = dE_dY[h,w,idx_k]\n",
    "            return dE_dk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563ea98b-22a2-44f3-9f42-2ee9db921f4c",
   "metadata": {},
   "source": [
    "# Sigmoid Layer Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3b4e462-8365-47a1-a26b-dd00e93f0be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLayer:\n",
    "    def __init__(self, input_units, output_units):\n",
    "        self.weight = np.random.randn(input_units, output_units)/input_units\n",
    "        self.bias = np.zeros(output_units)\n",
    "\n",
    "    def forward_prop(self, image):\n",
    "        self.original_shape = image.shape\n",
    "        image_flattened = image.flatten()\n",
    "        self.flattened_input = image_flattened\n",
    "        first_output = np.dot(image_flattened, self.weight) + self.bias\n",
    "        self.output = first_output\n",
    "        softmax_output = np.exp(first_output) / np.sum(np.exp(first_output), axis=0)\n",
    "        return softmax_output\n",
    "\n",
    "    def back_prop(self, dE_dY, alpha):\n",
    "        for i, gradient in enumerate(dE_dY):\n",
    "            if gradient == 0:\n",
    "                continue\n",
    "            transformation_eq = np.exp(self.output)\n",
    "            S_total = np.sum(transformation_eq)\n",
    "\n",
    "            dY_dZ = -transformation_eq[i]*transformation_eq / (S_total**2)\n",
    "            dY_dZ[i] = transformation_eq[i]*(S_total - transformation_eq[i]) / (S_total**2)\n",
    "\n",
    "            dZ_dw = self.flattened_input\n",
    "            dZ_db = 1\n",
    "            dZ_dX = self.weight\n",
    "\n",
    "            dE_dZ = gradient * dY_dZ\n",
    "\n",
    "            dE_dw = dZ_dw[np.newaxis].T @ dE_dZ[np.newaxis]\n",
    "            dE_db = dE_dZ * dZ_db\n",
    "            dE_dX = dZ_dX @ dE_dZ\n",
    "\n",
    "            self.weight -= alpha*dE_dw\n",
    "            self.bias -= alpha*dE_db\n",
    "\n",
    "            return dE_dX.reshape(self.original_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a401901c-cf5f-4ef3-8171-ddbdf31ea72b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2aa6b54-1588-4467-aaff-abe14a8d0bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_forward(image, label, layers):\n",
    "    output = image/255.\n",
    "    for layer in layers:\n",
    "        output = layer.forward_prop(output)\n",
    "    # Compute loss (cross-entropy) and accuracy\n",
    "    loss = -np.log(output[label])\n",
    "    accuracy = 1 if np.argmax(output) == label else 0\n",
    "    return output, loss, accuracy\n",
    "\n",
    "def CNN_backprop(gradient, layers, alpha=0.05):\n",
    "    grad_back = gradient\n",
    "    for layer in layers[::-1]:\n",
    "        if type(layer) in [ConvolutionLayer, SoftmaxLayer]:\n",
    "            grad_back = layer.back_prop(grad_back, alpha)\n",
    "        elif type(layer) == MaxPoolingLayer:\n",
    "            grad_back = layer.back_prop(grad_back)\n",
    "    return grad_back\n",
    "\n",
    "\n",
    "def CNN_training(image, label, layers, alpha=0.05):\n",
    "    # Forward step\n",
    "    output, loss, accuracy = CNN_forward(image, label, layers)\n",
    "\n",
    "    # Initial gradient\n",
    "    gradient = np.zeros(10)\n",
    "    gradient[label] = -1/output[label]\n",
    "\n",
    "    # Backprop step\n",
    "    gradient_back = CNN_backprop(gradient, layers, alpha)\n",
    "\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519f5859-6289-41eb-b1f7-e2ff1170bb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ->\n",
      "Step 1. For the last 100 steps: average loss 0.0, accuracy 0\n",
      "Step 101. For the last 100 steps: average loss 1.9457601928732688, accuracy 31\n",
      "Step 201. For the last 100 steps: average loss 1.1099547523925444, accuracy 66\n",
      "Step 301. For the last 100 steps: average loss 0.8588544734012631, accuracy 73\n",
      "Step 401. For the last 100 steps: average loss 0.6702594128858043, accuracy 81\n",
      "Step 501. For the last 100 steps: average loss 0.6197449615990956, accuracy 82\n",
      "Step 601. For the last 100 steps: average loss 0.5465531960343557, accuracy 82\n",
      "Step 701. For the last 100 steps: average loss 0.6697745852941723, accuracy 84\n",
      "Step 801. For the last 100 steps: average loss 0.5549596689319652, accuracy 83\n",
      "Step 901. For the last 100 steps: average loss 0.7651110588096691, accuracy 77\n",
      "Step 1001. For the last 100 steps: average loss 0.4561851566337857, accuracy 83\n",
      "Step 1101. For the last 100 steps: average loss 0.5197081394126561, accuracy 83\n",
      "Step 1201. For the last 100 steps: average loss 0.4714782026901996, accuracy 86\n",
      "Step 1301. For the last 100 steps: average loss 0.40431142268265013, accuracy 86\n",
      "Step 1401. For the last 100 steps: average loss 0.7203613934400265, accuracy 77\n",
      "Step 1501. For the last 100 steps: average loss 0.41817846324165514, accuracy 88\n",
      "Step 1601. For the last 100 steps: average loss 0.4885728762460814, accuracy 86\n",
      "Step 1701. For the last 100 steps: average loss 0.5219310287999283, accuracy 86\n",
      "Step 1801. For the last 100 steps: average loss 0.2517388048688946, accuracy 91\n",
      "Step 1901. For the last 100 steps: average loss 0.3120963609809607, accuracy 91\n",
      "Step 2001. For the last 100 steps: average loss 0.37530488800415385, accuracy 89\n",
      "Step 2101. For the last 100 steps: average loss 0.4612308889474439, accuracy 85\n",
      "Step 2201. For the last 100 steps: average loss 0.1841034733450384, accuracy 96\n",
      "Step 2301. For the last 100 steps: average loss 0.4255813832086643, accuracy 86\n",
      "Step 2401. For the last 100 steps: average loss 0.317584042363951, accuracy 90\n",
      "Step 2501. For the last 100 steps: average loss 0.33121983303985014, accuracy 94\n",
      "Step 2601. For the last 100 steps: average loss 0.27463268067728247, accuracy 93\n",
      "Step 2701. For the last 100 steps: average loss 0.4804207914831375, accuracy 85\n",
      "Step 2801. For the last 100 steps: average loss 0.3127102166315723, accuracy 90\n",
      "Step 2901. For the last 100 steps: average loss 0.3889566467256648, accuracy 89\n",
      "Step 3001. For the last 100 steps: average loss 0.3472568219893233, accuracy 88\n",
      "Step 3101. For the last 100 steps: average loss 0.49507505182379646, accuracy 86\n",
      "Step 3201. For the last 100 steps: average loss 0.5412492035631783, accuracy 89\n",
      "Step 3301. For the last 100 steps: average loss 0.29207440426207887, accuracy 90\n",
      "Step 3401. For the last 100 steps: average loss 0.43213660813271204, accuracy 85\n",
      "Step 3501. For the last 100 steps: average loss 0.48302546054552076, accuracy 84\n",
      "Step 3601. For the last 100 steps: average loss 0.40835607219872955, accuracy 89\n",
      "Step 3701. For the last 100 steps: average loss 0.3945173977256659, accuracy 88\n",
      "Step 3801. For the last 100 steps: average loss 0.6012272547756478, accuracy 83\n",
      "Step 3901. For the last 100 steps: average loss 0.338833827823971, accuracy 89\n",
      "Step 4001. For the last 100 steps: average loss 0.48879168021407493, accuracy 85\n",
      "Step 4101. For the last 100 steps: average loss 0.18711822912873546, accuracy 93\n",
      "Step 4201. For the last 100 steps: average loss 0.3100925670397879, accuracy 89\n",
      "Step 4301. For the last 100 steps: average loss 0.4648352166277025, accuracy 90\n",
      "Step 4401. For the last 100 steps: average loss 0.27258812154589285, accuracy 91\n",
      "Step 4501. For the last 100 steps: average loss 0.4345615025176328, accuracy 85\n",
      "Step 4601. For the last 100 steps: average loss 0.36872300506576855, accuracy 89\n",
      "Step 4701. For the last 100 steps: average loss 0.3603874226206583, accuracy 91\n",
      "Step 4801. For the last 100 steps: average loss 0.3086913401925553, accuracy 90\n",
      "Step 4901. For the last 100 steps: average loss 0.4290484787505082, accuracy 88\n",
      "Epoch 2 ->\n",
      "Step 1. For the last 100 steps: average loss 0.0, accuracy 0\n",
      "Step 101. For the last 100 steps: average loss 0.21313477182320908, accuracy 93\n",
      "Step 201. For the last 100 steps: average loss 0.2593556715114563, accuracy 95\n",
      "Step 301. For the last 100 steps: average loss 0.4015070761778137, accuracy 89\n",
      "Step 401. For the last 100 steps: average loss 0.2254090175146567, accuracy 94\n",
      "Step 501. For the last 100 steps: average loss 0.21381521285942326, accuracy 93\n",
      "Step 601. For the last 100 steps: average loss 0.25205440494239784, accuracy 92\n",
      "Step 701. For the last 100 steps: average loss 0.364111466043677, accuracy 88\n",
      "Step 801. For the last 100 steps: average loss 0.3099623244865873, accuracy 92\n",
      "Step 901. For the last 100 steps: average loss 0.33406489066242395, accuracy 90\n",
      "Step 1001. For the last 100 steps: average loss 0.1752821431388908, accuracy 93\n",
      "Step 1101. For the last 100 steps: average loss 0.2386282433233365, accuracy 92\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    X_train = X_train[:5000]\n",
    "    y_train = y_train[:5000]\n",
    "    \n",
    "    layers = [\n",
    "    ConvolutionLayer(16,3), # layer with 8 3x3 filters, output (26,26,16)\n",
    "    MaxPoolingLayer(2), # pooling layer 2x2, output (13,13,16)\n",
    "    SoftmaxLayer(13*13*16, 10) # softmax layer with 13*13*16 input and 10 output\n",
    "    ] \n",
    "    \n",
    "    for epoch in range(4):\n",
    "        print('Epoch {} ->'.format(epoch+1))\n",
    "    \n",
    "        permutation = np.random.permutation(len(X_train))\n",
    "        X_train = X_train[permutation]\n",
    "        y_train = y_train[permutation]\n",
    "    \n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "        for i, (image, label) in enumerate(zip(X_train, y_train)):\n",
    "            if i % 100 == 0: # Every 100 examples\n",
    "                print(\"Step {}. For the last 100 steps: average loss {}, accuracy {}\".format(i+1, loss/100, accuracy))\n",
    "                loss = 0\n",
    "                accuracy = 0\n",
    "            loss_1, accuracy_1 = CNN_training(image, label, layers)\n",
    "            loss += loss_1\n",
    "            accuracy += accuracy_1\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56064be3-5f63-4d91-a1bd-503934346c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
